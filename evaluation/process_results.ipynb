{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for aggregating a collection of HPC tasks on GraphWorld\n",
    "Given a type of experiment, this notebook takes all the json result files of a collection of HPC tasks and moves them into a single file in the `processed` directory. It also maintains a summary file in the same folder for all files for the experiment. Finally it loads the result files and prints basic statistics not part of the summary file (see last cell of this file).\n",
    "\n",
    "Set `RAW_DIR` to the raw experiments you want to process.\n",
    "\n",
    "Set `PROCESSED_DIR` to where the processed results should be stored.\n",
    "The processed results will be stored in shards. Each time this notebook is ran, 1 shard is created. E.g. the shard size depends on the contents of the `RAW_DIR`.\n",
    "\n",
    "The processing assumes that the raw results come from our HPC experimental setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = '-2-3-marg'\n",
    "RUN_TO_PROCESS = 'p_to_q_ratio_2'\n",
    "RAW_DIR = f'/home/data_shares/scara/graphworld/results/mode{mode}/raw/{RUN_TO_PROCESS}'\n",
    "PROCESSED_DIR = f'/home/data_shares/scara/graphworld/results/mode{mode}/processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Task/Graph statistics -------\n",
      "Total processed tasks: 100\n",
      "Total processed graphs: 442\n",
      "Graphs per task: 4.42\n",
      "Avg task runtime (min): 292.04 (66.07239819004525 per graph)\n",
      "Max task runtime (min): 804 (181.9004524886878 per graph)\n",
      "Min task runtime (min): 6 (1.3574660633484164 per graph)\n",
      "\n",
      "------- Skipped (crashed) methods -------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "import math\n",
    "\n",
    "PROCESSED_SHARDS = f'{PROCESSED_DIR}/shards'\n",
    "\n",
    "if not os.path.exists(PROCESSED_SHARDS):\n",
    "    os.makedirs(PROCESSED_SHARDS)\n",
    "\n",
    "# Read (existing) summary file for experiment\n",
    "try:\n",
    "    with open(f'{PROCESSED_DIR}/summary.json', 'r') as f:\n",
    "        summary = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    summary = {\n",
    "        'N_GRAPHS': 0,\n",
    "        'N_RUNS': 0,\n",
    "        'RUN_GRAPHS': [],\n",
    "        'RUN_MARG': [],\n",
    "        'RAW_FILES': []\n",
    "    }\n",
    "\n",
    "if RUN_TO_PROCESS in summary['RAW_FILES']:\n",
    "    raise Exception(f'WARNING: {RUN_TO_PROCESS} has already been processed!')\n",
    "\n",
    "summary['N_RUNS'] += 1\n",
    "summary['RAW_FILES'] += [RUN_TO_PROCESS]\n",
    "\n",
    "# Here we read the json shards of each HPC task, \n",
    "# aggregate them and store everything in one file in the processed folder\n",
    "lines = []\n",
    "results_file_regex = r'results\\.ndjson-(\\d{5})-of-(\\d{5})'\n",
    "successful_runs = []\n",
    "\n",
    "for sub_dir in next(os.walk(RAW_DIR))[1]:\n",
    "\tsub_dir_full = os.path.join(RAW_DIR, sub_dir)\n",
    "\tis_successful = False\n",
    "\tresult_files = filter(lambda file: re.match(results_file_regex, file), os.listdir(sub_dir_full))\n",
    "\tfor result_file in result_files:\n",
    "\t\twith open(os.path.join(sub_dir_full, result_file)) as f:\n",
    "\t\t\tlines.extend(f.readlines())\n",
    "\t\tis_successful = True\n",
    "\tif is_successful:\n",
    "\t\tsuccessful_runs += [sub_dir]\n",
    "                \n",
    "with open(f'{PROCESSED_DIR}/shards/{summary[\"N_RUNS\"]}.ndjson', \"w\") as dst:\n",
    "  for line in lines:\n",
    "    dst.write(line) # Write all graph experiments to same file\n",
    "\n",
    "# Load lines dataframe for printing statistics\n",
    "records = map(json.loads, lines)\n",
    "results_df = pd.DataFrame.from_records(records)\n",
    "\n",
    "# Getting running times\n",
    "times = []\n",
    "\n",
    "for task in next(os.walk(RAW_DIR))[1]:\n",
    "  if not task in successful_runs:\n",
    "     continue\n",
    "  with open(f'{RAW_DIR}/slurm_{task}.out', 'r') as f:\n",
    "    last_line = lines[-1].split(\" \")[1]\n",
    "    match = re.search(r'\\d+', last_line)\n",
    "\n",
    "    if match:\n",
    "      lines = f.readlines()\n",
    "      times.append(int(match.group()) // 60)\n",
    "    else:\n",
    "        print(f)\n",
    "    \n",
    "if len(times) == 0:\n",
    "    times = [math.nan]\n",
    "\n",
    "# Getting basic statistics of raw data\n",
    "N_GRAPHS = len(results_df)\n",
    "N_METHODS = len([col for col in results_df if 'encoder_hidden_channels' in col])\n",
    "N_TASKS = len(next(os.walk(RAW_DIR))[1])\n",
    "\n",
    "AVG_TIME = sum(times) / len(times)\n",
    "MAX_TIME = max(times)\n",
    "MIN_TIME = min(times)\n",
    "\n",
    "# Getting methods that have crashed / are skipped\n",
    "skipped_methods = {}\n",
    "for s_col in [col for col in results_df if '_skipped' in col]:\n",
    "    count = results_df[s_col].sum()\n",
    "    if count > 0:\n",
    "        skipped_methods.update({s_col.removesuffix('_skipped'): count})\n",
    "\n",
    "# Update summary file\n",
    "summary['N_GRAPHS'] += N_GRAPHS\n",
    "summary['RUN_GRAPHS'].append(N_GRAPHS)\n",
    "marg = results_df['marginal_param'].astype(str).unique()\n",
    "if len(marg) > 1:\n",
    "  summary['RUN_MARG'].append(\"mixed\")\n",
    "elif len(marg) == 0:\n",
    "  summary['RUN_MARG'].append([])\n",
    "else:\n",
    "  summary['RUN_MARG'].append(ast.literal_eval(marg[0]))\n",
    "\n",
    "with open(f'{PROCESSED_DIR}/summary.json', 'w') as s:\n",
    "  s.write(json.dumps(summary))\n",
    "\n",
    "\n",
    "# Printing statistics\n",
    "print('------- Task/Graph statistics -------')\n",
    "print(f'Total processed tasks: {N_TASKS}')\n",
    "print(f'Total processed graphs: {N_GRAPHS}')\n",
    "print(f'Graphs per task: {N_GRAPHS / N_TASKS}')\n",
    "print(f'Avg task runtime (min): {AVG_TIME} ({AVG_TIME / (N_GRAPHS / N_TASKS)} per graph)')\n",
    "print(f'Max task runtime (min): {MAX_TIME} ({MAX_TIME / (N_GRAPHS / N_TASKS)} per graph)')\n",
    "print(f'Min task runtime (min): {MIN_TIME} ({MIN_TIME / (N_GRAPHS / N_TASKS)} per graph)\\n')\n",
    "\n",
    "print('------- Skipped (crashed) methods -------')\n",
    "for k,v in skipped_methods.items():\n",
    "    print(f'{k} skipped {v} times')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
