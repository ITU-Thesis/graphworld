{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file allows for testing the GraphWorld setup with GNN implementations.\n",
    "It is currently set up to test the SSL methods for the JL benchmarker.\n",
    "\n",
    "Through this notebook you can attach a debugger.\n",
    "Note that graph_tool does not work on windows, so we cannot use the graph generators.\n",
    "Instead, we use the standard datasets from PyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from graph_world.self_supervised_learning.benchmarker_jl import NNNodeBenchmarkerJL\n",
    "from graph_world.models.basic_gnn import GCN\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "from graph_world.self_supervised_learning.pretext_tasks.auxiliary_property_based import *\n",
    "from graph_world.self_supervised_learning.pretext_tasks.contrastive_based_different_scale import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setup (for cora)\n",
    "benchmark_params = {\n",
    "    'epochs' : 50,\n",
    "    'lr' : 0.01,\n",
    "    'lambda' : 1\n",
    "}\n",
    "\n",
    "h_params = {\n",
    "    'in_channels' : 1433,\n",
    "    'hidden_channels' : 16,\n",
    "    'num_layers' : 2,\n",
    "    'dropout' : 0.5,\n",
    "    \"embedding_corruption_ratio\" : 0.1, \n",
    "    \"partial_embedding_reconstruction\" : True,\n",
    "    'n_parts': 10,\n",
    "    'shortest_path_cutoff': 6,\n",
    "    'N_classes': 4,\n",
    "    'k_largest': 20,\n",
    "    'k': 20,\n",
    "    'temperature': 1,\n",
    "    'num_cluster_iter': 500,\n",
    "    'alpha': 0.15,\n",
    "    'n_clusters': 30\n",
    "}\n",
    "\n",
    "generator_config = {\n",
    "    'num_clusters' : 7,\n",
    "}\n",
    "\n",
    "pretext_task = SUBG_CON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')[0]\n",
    "# dataset = KarateClub()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 10).unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(1433, 16, num_layers=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.9594218730926514,\n",
       "  2.945026397705078,\n",
       "  2.927903175354004,\n",
       "  2.889177083969116,\n",
       "  2.8705172538757324,\n",
       "  2.833305835723877,\n",
       "  2.767346143722534,\n",
       "  2.70845365524292,\n",
       "  2.6099300384521484,\n",
       "  2.5228404998779297,\n",
       "  2.5021626949310303,\n",
       "  2.285983085632324,\n",
       "  2.278137445449829,\n",
       "  2.0885391235351562,\n",
       "  2.017399549484253,\n",
       "  1.9704710245132446,\n",
       "  1.826206922531128,\n",
       "  1.6873406171798706,\n",
       "  1.636690378189087,\n",
       "  1.6233882904052734,\n",
       "  1.5277948379516602,\n",
       "  1.4642348289489746,\n",
       "  1.4291068315505981,\n",
       "  1.4705944061279297,\n",
       "  1.3830986022949219,\n",
       "  1.170853853225708,\n",
       "  1.279672622680664,\n",
       "  1.2527964115142822,\n",
       "  1.1010345220565796,\n",
       "  1.1427823305130005,\n",
       "  1.0715858936309814,\n",
       "  1.16620934009552,\n",
       "  1.0697882175445557,\n",
       "  1.0214099884033203,\n",
       "  0.832078754901886,\n",
       "  0.9366757869720459,\n",
       "  0.958958089351654,\n",
       "  0.9599683880805969,\n",
       "  0.8971724510192871,\n",
       "  0.9495126605033875,\n",
       "  0.9692106246948242,\n",
       "  0.9658770561218262,\n",
       "  0.8941949009895325,\n",
       "  0.9064047336578369,\n",
       "  0.9841784238815308,\n",
       "  0.8355443477630615,\n",
       "  0.9077608585357666,\n",
       "  0.9713150262832642,\n",
       "  0.8892596960067749,\n",
       "  1.0208262205123901],\n",
       " {'accuracy': 0.712,\n",
       "  'f1_micro': 0.712,\n",
       "  'f1_macro': 0.7104720987939109,\n",
       "  'rocauc_ovr': 0.8446711331896021,\n",
       "  'rocauc_ovo': 0.8446711331896021,\n",
       "  'logloss': 3.638101660192013},\n",
       " {'accuracy': 0.694,\n",
       "  'f1_micro': 0.694,\n",
       "  'f1_macro': 0.6872275612547518,\n",
       "  'rocauc_ovr': 0.8358069390741232,\n",
       "  'rocauc_ovo': 0.8358069390741232,\n",
       "  'logloss': 4.036672240257263})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training. You can attach a debugger to w/e is needed inside train\n",
    "benchmarker = NNNodeBenchmarkerJL(generator_config=generator_config, model_class=GCN, \n",
    "                benchmark_params=benchmark_params, h_params=h_params, pretext_task=pretext_task)\n",
    "                \n",
    "# benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=~dataset.train_mask, test_mask=~dataset.train_mask)\n",
    "benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=dataset.val_mask, test_mask=dataset.test_mask)\n",
    "benchmarker.train(data=dataset, tuning_metric=\"rocauc_ovr\", tuning_metric_is_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 1, 2, 3],\n",
       "        [1, 2, 3, 1, 2, 3]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3]\n",
    "])\n",
    "\n",
    "torch.concat([A, A], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "\n",
      "4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch import tensor\n",
    "from torch_geometric.nn import GraphConv, global_mean_pool\n",
    "\n",
    "X = torch.tensor([\n",
    "    [0],\n",
    "    [1],\n",
    "    [2],\n",
    "    [3],\n",
    "    [4]\n",
    "], dtype=torch.float32)\n",
    "edge_index_s = torch.tensor([\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 2, 3, 4],\n",
    "])\n",
    "edge_index_t = torch.tensor([\n",
    "    [0, 0, 0],\n",
    "    [1, 2, 3],\n",
    "])\n",
    "\n",
    "\n",
    "a = Data(x=X[0:2], edge_index=edge_index_s) # [0, 1]\n",
    "b = Data(x=X[1:], edge_index=edge_index_t) # [1, 2, 3, 4]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch = Batch.from_data_list([a, b])\n",
    "model = GraphConv(in_channels=1, out_channels=1)\n",
    "H = model(x=batch.x, edge_index=batch.edge_index)\n",
    "for x in DataLoader(batch):\n",
    "    print(x.x.shape[0])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.data.batch.DataBatch"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, -1, -2],\n",
       "        [ 1,  0, -1],\n",
       "        [ 2,  1,  0]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([\n",
    "    [1],\n",
    "    [2],\n",
    "    [3]\n",
    "])\n",
    "\n",
    "\n",
    "a - a.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1],\n",
       "         [2],\n",
       "         [3]]),\n",
       " tensor([[1, 2, 3]]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21336\\3816458505.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Training. You can attach a debugger to w/e is needed inside train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m benchmarker = NNNodeBenchmarkerJL(generator_config=generator_config, model_class=GCN, \n\u001b[0m\u001b[0;32m      3\u001b[0m                 benchmark_params=benchmark_params, h_params=h_params, pretext_task=pretext_task)\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=~dataset.train_mask, test_mask=~dataset.train_mask)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generator_config' is not defined"
     ]
    }
   ],
   "source": [
    "# Training. You can attach a debugger to w/e is needed inside train\n",
    "benchmarker = NNNodeBenchmarkerJL(generator_config=generator_config, model_class=GCN, \n",
    "                benchmark_params=benchmark_params, h_params=h_params, pretext_task=pretext_task)\n",
    "                \n",
    "# benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=~dataset.train_mask, test_mask=~dataset.train_mask)\n",
    "benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=dataset.val_mask, test_mask=dataset.test_mask)\n",
    "benchmarker.train(data=dataset, tuning_metric=\"rocauc_ovr\", tuning_metric_is_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d9defa72c2715dab9f7f172572cd30a1ab1a2083462d32ef96aadb7c6e0c73b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
