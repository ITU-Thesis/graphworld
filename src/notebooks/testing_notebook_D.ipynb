{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file allows for testing the GraphWorld setup with GNN implementations.\n",
    "It is currently set up to test the SSL methods for the JL benchmarker.\n",
    "\n",
    "Through this notebook you can attach a debugger.\n",
    "Note that graph_tool does not work on windows, so we cannot use the graph generators.\n",
    "Instead, we use the standard datasets from PyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from graph_world.self_supervised_learning.benchmarker_jl import NNNodeBenchmarkerJL\n",
    "from graph_world.models.basic_gnn import GCN\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "from graph_world.self_supervised_learning.pretext_tasks.auxiliary_property_based import *\n",
    "from graph_world.self_supervised_learning.pretext_tasks.contrastive_based_different_scale import *\n",
    "from graph_world.self_supervised_learning.pretext_tasks.hybrid import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setup (for cora)\n",
    "benchmark_params = {\n",
    "    'epochs' : 3_000,\n",
    "    'lr' : 0.001,\n",
    "    'lambda' : 1\n",
    "}\n",
    "\n",
    "h_params = {\n",
    "    'in_channels' : 1433,\n",
    "    'hidden_channels' : 128,\n",
    "    'num_layers' : 2,\n",
    "    'dropout' : 0.5,\n",
    "    \"embedding_corruption_ratio\" : 0.1, \n",
    "    \"partial_embedding_reconstruction\" : True,\n",
    "    'n_parts': 10,\n",
    "    'shortest_path_cutoff': 6,\n",
    "    'N_classes': 4,\n",
    "    'k_largest': 20,\n",
    "    'k': 20,\n",
    "    'temperature': 1,\n",
    "    'num_cluster_iter': 500,\n",
    "    'alpha': 0.15,\n",
    "    'n_clusters': 30,\n",
    "    'num_iter': 10,\n",
    "    'n_partitions': 8,\n",
    "    'B': 200,\n",
    "    'k': 8,\n",
    "    'P': 2000,\n",
    "    'alpha': 0.8,\n",
    "    'micro_meso_macro_weights': [1, 1, 1]\n",
    "}\n",
    "\n",
    "generator_config = {\n",
    "    'num_clusters' : 7,\n",
    "}\n",
    "\n",
    "pretext_task = G_Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')[0]\n",
    "# dataset = KarateClub()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training. You can attach a debugger to w/e is needed inside train\n",
    "benchmarker = NNNodeBenchmarkerJL(generator_config=generator_config, model_class=GCN, \n",
    "                benchmark_params=benchmark_params, h_params=h_params, pretext_task=pretext_task)\n",
    "                \n",
    "# benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=~dataset.train_mask, test_mask=~dataset.train_mask)\n",
    "benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=dataset.val_mask, test_mask=dataset.test_mask)\n",
    "benchmarker.train(data=dataset, tuning_metric=\"rocauc_ovr\", tuning_metric_is_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'batchh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'batchh'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3616\\3047010653.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGraphConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatchh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\torch_geometric\\data\\data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;34m\"dataset, remove the 'processed/' directory in the dataset's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m                 \"root folder and try again.\")\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\danie\\anaconda3\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             raise AttributeError(\n\u001b[0m\u001b[0;32m     64\u001b[0m                 f\"'{self.__class__.__name__}' object has no attribute '{key}'\")\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'batchh'"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch import tensor\n",
    "from torch_geometric.nn import GraphConv, global_mean_pool\n",
    "\n",
    "X = torch.tensor([\n",
    "    [0],\n",
    "    [1],\n",
    "    [2],\n",
    "    [3],\n",
    "    [4]\n",
    "], dtype=torch.float32)\n",
    "edge_index_s = torch.tensor([\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 2, 3, 4],\n",
    "])\n",
    "edge_index_t = torch.tensor([\n",
    "    [0, 0, 0],\n",
    "    [1, 2, 3],\n",
    "])\n",
    "\n",
    "\n",
    "a = Data(x=X[0:2], edge_index=edge_index_s) # [0, 1]\n",
    "b = Data(x=X[1:], edge_index=edge_index_t) # [1, 2, 3, 4]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch = Batch.from_data_list([a, b])\n",
    "model = GraphConv(in_channels=1, out_channels=1)\n",
    "H = model(x=batch.x, edge_index=batch.edge_index)\n",
    "batch.batchh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   0,  633, 1862, 2582]),\n",
       " tensor([[0, 0, 0, 1, 2, 2, 3, 3],\n",
       "         [1, 2, 3, 0, 0, 3, 0, 2]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "k_hop_subgraph([0], edge_index=dataset.edge_index, num_hops=1, relabel_nodes=True)[0:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d9defa72c2715dab9f7f172572cd30a1ab1a2083462d32ef96aadb7c6e0c73b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
