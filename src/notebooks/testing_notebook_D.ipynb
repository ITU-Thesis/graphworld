{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file allows for testing the GraphWorld setup with GNN implementations.\n",
    "It is currently set up to test the SSL methods for the JL benchmarker.\n",
    "\n",
    "Through this notebook you can attach a debugger.\n",
    "Note that graph_tool does not work on windows, so we cannot use the graph generators.\n",
    "Instead, we use the standard datasets from PyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from graph_world.self_supervised_learning.benchmarker_jl import NNNodeBenchmarkerJL\n",
    "from graph_world.models.basic_gnn import GCN\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "from graph_world.self_supervised_learning.pretext_tasks.auxiliary_property_based import *\n",
    "from graph_world.self_supervised_learning.pretext_tasks.contrastive_based_different_scale import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setup (for cora)\n",
    "benchmark_params = {\n",
    "    'epochs' : 10,\n",
    "    'lr' : 0.01,\n",
    "    'lambda' : 1\n",
    "}\n",
    "\n",
    "h_params = {\n",
    "    'in_channels' : 1433,\n",
    "    'hidden_channels' : 16,\n",
    "    'num_layers' : 2,\n",
    "    'dropout' : 0.5,\n",
    "    \"embedding_corruption_ratio\" : 0.1, \n",
    "    \"partial_embedding_reconstruction\" : True,\n",
    "    'n_parts': 10,\n",
    "    'shortest_path_cutoff': 6,\n",
    "    'N_classes': 4,\n",
    "    'k_largest': 20,\n",
    "    'k': 15,\n",
    "    'temperature': 1,\n",
    "    'num_cluster_iter': 500,\n",
    "    'alpha': 0.15,\n",
    "    'n_clusters': 30\n",
    "}\n",
    "\n",
    "generator_config = {\n",
    "    'num_clusters' : 7,\n",
    "}\n",
    "\n",
    "pretext_task = DeepGraphInfomax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')[0]\n",
    "# dataset = KarateClub()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "class AvgNeighbor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AvgNeighbor, self).__init__()\n",
    "\n",
    "    def forward(self, seq, adj_ori):\n",
    "        if torch.cuda.is_available():\n",
    "            adj_ori = adj_ori.cuda()\n",
    "        return torch.unsqueeze(torch.spmm(adj_ori, torch.squeeze(seq, 0)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.x[[0, 0, 0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (*, torch.device device)\n * (Tensor indices, Tensor values, *, torch.device device)\n * (Tensor indices, Tensor values, tuple of ints size, *, torch.device device)\n * (tuple of ints size, *, torch.device device)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13712\\2493724452.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (*, torch.device device)\n * (Tensor indices, Tensor values, *, torch.device device)\n * (Tensor indices, Tensor values, tuple of ints size, *, torch.device device)\n * (tuple of ints size, *, torch.device device)\n"
     ]
    }
   ],
   "source": [
    "c = AvgNeighbor()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(1433, 16, num_layers=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:90: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(Adam, self).__init__(params, defaults)\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py:160: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::zeros         0.88%       2.311ms         1.17%       3.078ms      66.913us            46  \n",
      "                                            aten::empty         0.54%       1.421ms         0.54%       1.421ms       3.116us           456  \n",
      "                                            aten::zero_         0.10%     251.000us         0.42%       1.096ms      11.913us            92  \n",
      "                                          ProfilerStep*        39.58%     104.010ms        99.20%     260.723ms     130.362ms             2  \n",
      "                     Optimizer.zero_grad#Adam.zero_grad         0.15%     391.000us         0.19%     491.000us     245.500us             2  \n",
      "                                             aten::ones         0.16%     408.000us         0.29%     762.000us      38.100us            20  \n",
      "                                            aten::fill_         0.52%       1.379ms         0.52%       1.379ms      11.492us           120  \n",
      "                                           aten::select         0.72%       1.891ms         0.92%       2.426ms       7.629us           318  \n",
      "                                       aten::as_strided         0.59%       1.540ms         0.59%       1.540ms       1.825us           844  \n",
      "                                               aten::ne         0.37%     985.000us         0.37%     985.000us      49.250us            20  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 262.814ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py:160: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::zeros         0.13%     450.000us         0.46%       1.572ms      24.562us            64  \n",
      "                                            aten::empty         0.67%       2.265ms         0.67%       2.265ms       3.528us           642  \n",
      "                                            aten::zero_         0.09%     313.000us         0.46%       1.547ms      11.632us           133  \n",
      "                                          ProfilerStep*        35.10%     119.067ms        99.97%     339.130ms     169.565ms             2  \n",
      "                     Optimizer.zero_grad#Adam.zero_grad         0.10%     339.000us         0.13%     433.000us     144.333us             3  \n",
      "                                             aten::ones         0.08%     279.000us         0.24%     817.000us      29.179us            28  \n",
      "                                            aten::fill_         0.59%       2.006ms         0.59%       2.006ms      11.663us           172  \n",
      "                                           aten::select         0.67%       2.259ms         0.89%       3.033ms       6.785us           447  \n",
      "                                       aten::as_strided         0.78%       2.646ms         0.78%       2.646ms       2.220us          1192  \n",
      "                                               aten::ne         0.30%       1.028ms         0.30%       1.028ms      36.714us            28  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 339.216ms\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py:160: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3.360574245452881,\n",
       "  3.327719211578369,\n",
       "  3.276233196258545,\n",
       "  3.229010581970215,\n",
       "  3.1075940132141113,\n",
       "  2.993231773376465,\n",
       "  2.928018808364868,\n",
       "  2.830142021179199,\n",
       "  2.616269588470459,\n",
       "  2.595198154449463],\n",
       " {'accuracy': 0.642,\n",
       "  'f1_micro': 0.642,\n",
       "  'f1_macro': 0.6047545919642572,\n",
       "  'rocauc_ovr': 0.7926955713042793,\n",
       "  'rocauc_ovo': 0.7926955713042793,\n",
       "  'logloss': 2.7923250497430563},\n",
       " {'accuracy': 0.59,\n",
       "  'f1_micro': 0.59,\n",
       "  'f1_macro': 0.5592747802505944,\n",
       "  'rocauc_ovr': 0.7696136704594043,\n",
       "  'rocauc_ovo': 0.7696136704594043,\n",
       "  'logloss': 3.346689196899533})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training. You can attach a debugger to w/e is needed inside train\n",
    "benchmarker = NNNodeBenchmarkerJL(generator_config=generator_config, model_class=GCN, \n",
    "                benchmark_params=benchmark_params, h_params=h_params, pretext_task=pretext_task)\n",
    "                \n",
    "# benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=~dataset.train_mask, test_mask=~dataset.train_mask)\n",
    "benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=dataset.val_mask, test_mask=dataset.test_mask)\n",
    "benchmarker.train(data=dataset, tuning_metric=\"rocauc_ovr\", tuning_metric_is_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d9defa72c2715dab9f7f172572cd30a1ab1a2083462d32ef96aadb7c6e0c73b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
