{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file allows for testing the GraphWorld setup with GNN implementations.\n",
    "It is currently set up to test the SSL methods for the JL benchmarker.\n",
    "\n",
    "Through this notebook you can attach a debugger.\n",
    "Note that graph_tool does not work on windows, so we cannot use the graph generators.\n",
    "Instead, we use the standard datasets from PyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from graph_world.self_supervised_learning.benchmarker_jl import NNNodeBenchmarkerJL\n",
    "from graph_world.models.basic_gnn import GCN, SuperGAT\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "from graph_world.self_supervised_learning.pretext_tasks.contrastive_based import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setup (for cora)\n",
    "benchmark_params = {\n",
    "    'epochs' : 50,\n",
    "    'lr' : 0.01,\n",
    "    'lambda' : 0.5\n",
    "}\n",
    "\n",
    "h_params = {\n",
    "    'in_channels' : 1433,\n",
    "    'hidden_channels' : 16,\n",
    "    'num_layers' : 2,\n",
    "    'dropout' : 0.5,\n",
    "    'tau' : 0.5, \n",
    "    'edge_mask_ratio1' : 0.2,\n",
    "    'edge_mask_ratio2' : 0.4,\n",
    "    'feature_mask_ratio1' : 0.4, \n",
    "    'feature_mask_ratio2' : 0.2\n",
    "}\n",
    "\n",
    "generator_config = {\n",
    "    'num_clusters' : 7,\n",
    "}\n",
    "\n",
    "pretext_tasks = [GRACE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(1433, 16, num_layers=2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m benchmarker \u001b[39m=\u001b[39m NNNodeBenchmarkerJL(generator_config\u001b[39m=\u001b[39mgenerator_config, model_class\u001b[39m=\u001b[39mGCN, \n\u001b[0;32m      3\u001b[0m                 benchmark_params\u001b[39m=\u001b[39mbenchmark_params, h_params\u001b[39m=\u001b[39mh_params, pretext_tasks\u001b[39m=\u001b[39mpretext_tasks)\n\u001b[0;32m      4\u001b[0m benchmarker\u001b[39m.\u001b[39mSetMasks(train_mask\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mtrain_mask, val_mask\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mval_mask, test_mask\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mtest_mask)\n\u001b[1;32m----> 5\u001b[0m benchmarker\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49mdataset, tuning_metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrocauc_ovr\u001b[39;49m\u001b[39m\"\u001b[39;49m, tuning_metric_is_loss\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\dev\\kandidat\\thesis\\graphworld\\src\\graph_world\\self_supervised_learning\\benchmarker_jl.py:171\u001b[0m, in \u001b[0;36mNNNodeBenchmarkerJL.train\u001b[1;34m(self, data, tuning_metric, tuning_metric_is_loss)\u001b[0m\n\u001b[0;32m    169\u001b[0m best_val_metrics \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n\u001b[1;32m--> 171\u001b[0m   losses\u001b[39m.\u001b[39mappend(\u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(data)))\n\u001b[0;32m    172\u001b[0m   val_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest(data, test_on_val\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    173\u001b[0m   \u001b[39mif\u001b[39;00m ((tuning_metric_is_loss \u001b[39mand\u001b[39;00m val_metrics[tuning_metric] \u001b[39m<\u001b[39m best_val_metric) \u001b[39mor\u001b[39;00m\n\u001b[0;32m    174\u001b[0m       (\u001b[39mnot\u001b[39;00m tuning_metric_is_loss \u001b[39mand\u001b[39;00m val_metrics[tuning_metric] \u001b[39m>\u001b[39m best_val_metric)):\n",
      "File \u001b[1;32mc:\\dev\\kandidat\\thesis\\graphworld\\src\\graph_world\\self_supervised_learning\\benchmarker_jl.py:102\u001b[0m, in \u001b[0;36mNNNodeBenchmarkerJL.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39m# Add pretext losses\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m pm \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pretext_models:\n\u001b[1;32m--> 102\u001b[0m   loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lambda \u001b[39m*\u001b[39m pm\u001b[39m.\u001b[39;49mmake_loss(embeddings)\n\u001b[0;32m    104\u001b[0m \u001b[39m# Update parameters\u001b[39;00m\n\u001b[0;32m    105\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\dev\\kandidat\\thesis\\graphworld\\src\\graph_world\\self_supervised_learning\\pretext_tasks\\contrastive_based.py:76\u001b[0m, in \u001b[0;36mGRACE.make_loss\u001b[1;34m(self, embeddings)\u001b[0m\n\u001b[0;32m     73\u001b[0m h2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder_projection(z2)\n\u001b[0;32m     75\u001b[0m \u001b[39m# Compute loss\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m l1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_InfoNCE_loss(h1, h2)\n\u001b[0;32m     77\u001b[0m l2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_InfoNCE_loss(h2, h1)\n\u001b[0;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m ((l1 \u001b[39m+\u001b[39m l2) \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\dev\\kandidat\\thesis\\graphworld\\src\\graph_world\\self_supervised_learning\\pretext_tasks\\contrastive_based.py:59\u001b[0m, in \u001b[0;36mGRACE.compute_InfoNCE_loss\u001b[1;34m(self, z1, z2)\u001b[0m\n\u001b[0;32m     55\u001b[0m refl_sim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexp(torch\u001b[39m.\u001b[39mmm(z1, z1\u001b[39m.\u001b[39mt()) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtau) \u001b[39m# inter-view\u001b[39;00m\n\u001b[0;32m     56\u001b[0m between_sim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexp(torch\u001b[39m.\u001b[39mmm(z1, z2\u001b[39m.\u001b[39mt()) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtau) \u001b[39m# intra-view\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39mlog(\n\u001b[1;32m---> 59\u001b[0m     between_sim\u001b[39m.\u001b[39mdiag() \u001b[39m/\u001b[39m (refl_sim(\u001b[39m1\u001b[39;49m) \u001b[39m+\u001b[39m between_sim\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m refl_sim\u001b[39m.\u001b[39mdiag())\n\u001b[0;32m     60\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "# Training. You can attach a debugger to w/e is needed inside train\n",
    "benchmarker = NNNodeBenchmarkerJL(generator_config=generator_config, model_class=GCN, \n",
    "                benchmark_params=benchmark_params, h_params=h_params, pretext_tasks=pretext_tasks)\n",
    "benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=dataset.val_mask, test_mask=dataset.test_mask)\n",
    "benchmarker.train(data=dataset, tuning_metric=\"rocauc_ovr\", tuning_metric_is_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7ab25521b35298f0c482908cd2836fcd803c6b8449977de01eb4d32cc96d8dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
