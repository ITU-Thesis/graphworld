{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file allows for testing the GraphWorld setup with GNN implementations.\n",
    "It is currently set up to test the SSL methods for the JL benchmarker.\n",
    "\n",
    "Through this notebook you can attach a debugger.\n",
    "Note that graph_tool does not work on windows, so we cannot use the graph generators.\n",
    "Instead, we use the standard datasets from PyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from graph_world.self_supervised_learning.benchmarker import NNNodeBenchmarkerSSL\n",
    "from graph_world.models.basic_gnn import GCN, SuperGAT\n",
    "from torch_geometric.datasets import Planetoid, KarateClub, FakeDataset\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "from graph_world.self_supervised_learning.pretext_tasks.auxiliary_property_based import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = FakeDataset(num_graphs = 1, avg_num_nodes = 100, num_channels = 16, num_classes = 4)[0]\n",
    "dataset = RandomNodeSplit(split = \"random\", num_test = 20, num_val = 20, num_train_per_class=2)(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setup (for cora)\n",
    "benchmark_params = {\n",
    "    'downstream_epochs' : 200,\n",
    "    'pretext_epochs' : 200,\n",
    "    'downstream_lr' : 3e-4,\n",
    "    'pretext_lr' : 3e-4,\n",
    "    'patience': 100\n",
    "}\n",
    "\n",
    "h_params = {\n",
    "    'in_channels' : dataset.x.shape[1],\n",
    "    'hidden_channels' : 128,\n",
    "    'num_layers' : 2,\n",
    "    'dropout' : 0.5,\n",
    "}\n",
    "\n",
    "pretext_params = {\n",
    "    'k_largest': 3,\n",
    "}\n",
    "\n",
    "generator_config = {\n",
    "    'num_clusters' : 4,\n",
    "}\n",
    "\n",
    "pretext_task = PairwiseAttrSim\n",
    "training_scheme = 'JL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PairwiseAttrSim.__init__() missing 1 required positional argument: 'k_largest'\n  No values supplied by Gin or caller for arguments: ['k_largest']\n  Gin had values bound for: []\n  Caller supplied values for: ['ae_loss_weight', 'data', 'embedding_mask_ratio', 'encoder', 'epochs', 'er_loss_weight', 'feature_mask_ratio', 'fr_loss_weight', 'partial_reconstruction', 'pretext_weight', 'self', 'train_mask']\n  In call to configurable 'PairwiseAttrSim' (<class 'graph_world.self_supervised_learning.pretext_tasks.auxiliary_property_based.PairwiseAttrSim'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m benchmarker \u001b[39m=\u001b[39m NNNodeBenchmarkerSSL(generator_config\u001b[39m=\u001b[39mgenerator_config, model_class\u001b[39m=\u001b[39mGCN, \n\u001b[0;32m      3\u001b[0m                 benchmark_params\u001b[39m=\u001b[39mbenchmark_params, h_params\u001b[39m=\u001b[39mh_params,\n\u001b[0;32m      4\u001b[0m                 pretext_task\u001b[39m=\u001b[39mpretext_task, pretext_params \u001b[39m=\u001b[39m pretext_params, training_scheme\u001b[39m=\u001b[39mtraining_scheme)\n\u001b[0;32m      5\u001b[0m benchmarker\u001b[39m.\u001b[39mSetMasks(train_mask\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mtrain_mask, val_mask\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mval_mask, test_mask\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mtest_mask)\n\u001b[1;32m----> 6\u001b[0m benchmarker\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49mdataset, tuning_metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrocauc_ovr\u001b[39;49m\u001b[39m\"\u001b[39;49m, tuning_metric_is_loss\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\dev\\kandidat\\thesis\\graphworld\\src\\graph_world\\self_supervised_learning\\benchmarker.py:187\u001b[0m, in \u001b[0;36mNNNodeBenchmarkerSSL.train\u001b[1;34m(self, data, tuning_metric, tuning_metric_is_loss)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pretext_h_params[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data\n\u001b[0;32m    186\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pretext_h_params[\u001b[39m'\u001b[39m\u001b[39mtrain_mask\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_mask\n\u001b[1;32m--> 187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pretext_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pretext_task(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pretext_h_params) \u001b[39m# init pretext with hparams\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39m# Setup downstream decoder\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_downstream_decoder \u001b[39m=\u001b[39m Linear(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pretext_model\u001b[39m.\u001b[39mget_embedding_dim(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_downstream_out)\n",
      "File \u001b[1;32mc:\\Users\\bertr\\miniconda3\\envs\\thesis\\lib\\site-packages\\gin\\config.py:1605\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m scope_info \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m in scope \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(scope_str) \u001b[39mif\u001b[39;00m scope_str \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1604\u001b[0m err_str \u001b[39m=\u001b[39m err_str\u001b[39m.\u001b[39mformat(name, fn_or_cls, scope_info)\n\u001b[1;32m-> 1605\u001b[0m utils\u001b[39m.\u001b[39;49maugment_exception_message_and_reraise(e, err_str)\n",
      "File \u001b[1;32mc:\\Users\\bertr\\miniconda3\\envs\\thesis\\lib\\site-packages\\gin\\utils.py:41\u001b[0m, in \u001b[0;36maugment_exception_message_and_reraise\u001b[1;34m(exception, message)\u001b[0m\n\u001b[0;32m     39\u001b[0m proxy \u001b[39m=\u001b[39m ExceptionProxy()\n\u001b[0;32m     40\u001b[0m ExceptionProxy\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(exception)\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[1;32m---> 41\u001b[0m \u001b[39mraise\u001b[39;00m proxy\u001b[39m.\u001b[39mwith_traceback(exception\u001b[39m.\u001b[39m__traceback__) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bertr\\miniconda3\\envs\\thesis\\lib\\site-packages\\gin\\config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[0;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: PairwiseAttrSim.__init__() missing 1 required positional argument: 'k_largest'\n  No values supplied by Gin or caller for arguments: ['k_largest']\n  Gin had values bound for: []\n  Caller supplied values for: ['ae_loss_weight', 'data', 'embedding_mask_ratio', 'encoder', 'epochs', 'er_loss_weight', 'feature_mask_ratio', 'fr_loss_weight', 'partial_reconstruction', 'pretext_weight', 'self', 'train_mask']\n  In call to configurable 'PairwiseAttrSim' (<class 'graph_world.self_supervised_learning.pretext_tasks.auxiliary_property_based.PairwiseAttrSim'>)"
     ]
    }
   ],
   "source": [
    "# Training. You can attach a debugger to w/e is needed inside train\n",
    "benchmarker = NNNodeBenchmarkerSSL(generator_config=generator_config, model_class=GCN, \n",
    "                benchmark_params=benchmark_params, h_params=h_params,\n",
    "                pretext_task=pretext_task, pretext_params = pretext_params, training_scheme=training_scheme)\n",
    "benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=dataset.val_mask, test_mask=dataset.test_mask)\n",
    "benchmarker.train(data=dataset, tuning_metric=\"rocauc_ovr\", tuning_metric_is_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7ab25521b35298f0c482908cd2836fcd803c6b8449977de01eb4d32cc96d8dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
