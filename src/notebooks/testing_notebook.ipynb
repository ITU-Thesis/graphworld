{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file allows for testing the GraphWorld setup with GNN implementations.\n",
    "It is currently set up to test the SSL methods for the JL benchmarker.\n",
    "\n",
    "Through this notebook you can attach a debugger.\n",
    "Note that graph_tool does not work on windows, so we cannot use the graph generators.\n",
    "Instead, we use the standard datasets from PyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from graph_world.nodeclassification.benchmarker_jl import NNNodeBenchmarkerJL\n",
    "from graph_world.models.basic_gnn import GCN\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "from graph_world.self_supervised_learning.pretext_tasks import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setup (for cora)\n",
    "benchmark_params = {\n",
    "    'epochs' : 50,\n",
    "    'lr' : 0.01,\n",
    "    'lambda' : 0.1\n",
    "}\n",
    "\n",
    "h_params = {\n",
    "    'in_channels' : 1433,\n",
    "    'hidden_channels' : 16,\n",
    "    'num_layers' : 2,\n",
    "    'dropout' : 0.5,\n",
    "}\n",
    "\n",
    "generator_config = {\n",
    "    'num_clusters' : 7\n",
    "}\n",
    "\n",
    "pretext_tasks = [AttributeMask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(1433, 7, num_layers=2)\n",
      "GCN(1433, 16, num_layers=2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m benchmarker \u001b[39m=\u001b[39m NNNodeBenchmarkerJL(generator_config\u001b[39m=\u001b[39mgenerator_config, model_class\u001b[39m=\u001b[39mGCN, \n\u001b[0;32m      3\u001b[0m                 benchmark_params\u001b[39m=\u001b[39mbenchmark_params, h_params\u001b[39m=\u001b[39mh_params, pretext_tasks\u001b[39m=\u001b[39mpretext_tasks)\n\u001b[0;32m      4\u001b[0m benchmarker\u001b[39m.\u001b[39mSetMasks(train_mask\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mtrain_mask, val_mask\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mval_mask, test_mask\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mtest_mask)\n\u001b[1;32m----> 5\u001b[0m benchmarker\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49mdataset, tuning_metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrocauc_ovr\u001b[39;49m\u001b[39m\"\u001b[39;49m, tuning_metric_is_loss\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\dev\\kandidat\\thesis\\graphworld\\src\\graph_world\\nodeclassification\\benchmarker_jl.py:135\u001b[0m, in \u001b[0;36mNNNodeBenchmarkerJL.train\u001b[1;34m(self, data, tuning_metric, tuning_metric_is_loss)\u001b[0m\n\u001b[0;32m    133\u001b[0m best_val_metrics \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n\u001b[1;32m--> 135\u001b[0m   losses\u001b[39m.\u001b[39mappend(\u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(data)))\n\u001b[0;32m    136\u001b[0m   val_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest(data, test_on_val\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    137\u001b[0m   \u001b[39mif\u001b[39;00m ((tuning_metric_is_loss \u001b[39mand\u001b[39;00m val_metrics[tuning_metric] \u001b[39m<\u001b[39m best_val_metric) \u001b[39mor\u001b[39;00m\n\u001b[0;32m    138\u001b[0m       (\u001b[39mnot\u001b[39;00m tuning_metric_is_loss \u001b[39mand\u001b[39;00m val_metrics[tuning_metric] \u001b[39m>\u001b[39m best_val_metric)):\n",
      "File \u001b[1;32mc:\\dev\\kandidat\\thesis\\graphworld\\src\\graph_world\\nodeclassification\\benchmarker_jl.py:67\u001b[0m, in \u001b[0;36mNNNodeBenchmarkerJL.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39m# Add pretext losses\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m pm \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pretext_models:\n\u001b[1;32m---> 67\u001b[0m   loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lambda \u001b[39m*\u001b[39m pm\u001b[39m.\u001b[39;49mmake_loss(embeddings)\n\u001b[0;32m     69\u001b[0m \u001b[39m# Update parameters\u001b[39;00m\n\u001b[0;32m     70\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\dev\\kandidat\\thesis\\graphworld\\src\\graph_world\\self_supervised_learning\\pretext_tasks.py:58\u001b[0m, in \u001b[0;36mAttributeMask.make_loss\u001b[1;34m(self, embeddings)\u001b[0m\n\u001b[0;32m     56\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39medge_index)\n\u001b[0;32m     57\u001b[0m y_hat \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(z[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasked_nodes]))\n\u001b[1;32m---> 58\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmse_loss(y_hat, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpseudo_labels, reduction\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     59\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\bertr\\miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\functional.py:3281\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3277\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, target):\n\u001b[0;32m   3278\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   3279\u001b[0m         mse_loss, (\u001b[39minput\u001b[39m, target), \u001b[39minput\u001b[39m, target, size_average\u001b[39m=\u001b[39msize_average, reduce\u001b[39m=\u001b[39mreduce, reduction\u001b[39m=\u001b[39mreduction\n\u001b[0;32m   3280\u001b[0m     )\n\u001b[1;32m-> 3281\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (target\u001b[39m.\u001b[39;49msize() \u001b[39m==\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()):\n\u001b[0;32m   3282\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   3283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3284\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3285\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()),\n\u001b[0;32m   3286\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   3287\u001b[0m     )\n\u001b[0;32m   3288\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "# Training. You can attach a debugger to w/e is needed inside train\n",
    "benchmarker = NNNodeBenchmarkerJL(generator_config=generator_config, model_class=GCN, \n",
    "                benchmark_params=benchmark_params, h_params=h_params, pretext_tasks=pretext_tasks)\n",
    "benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=dataset.val_mask, test_mask=dataset.test_mask)\n",
    "benchmarker.train(data=dataset, tuning_metric=\"rocauc_ovr\", tuning_metric_is_loss=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7ab25521b35298f0c482908cd2836fcd803c6b8449977de01eb4d32cc96d8dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
