{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file allows for testing the GraphWorld setup with GNN implementations.\n",
    "It is currently set up to test the SSL methods for the JL benchmarker.\n",
    "\n",
    "Through this notebook you can attach a debugger.\n",
    "Note that graph_tool does not work on windows, so we cannot use the graph generators.\n",
    "Instead, we use the standard datasets from PyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from graph_world.self_supervised_learning.benchmarker import NNNodeBenchmarkerSSL\n",
    "from graph_world.models.basic_gnn import GCN, SuperGAT\n",
    "from torch_geometric.datasets import Planetoid, KarateClub, FakeDataset\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "from graph_world.self_supervised_learning.pretext_tasks.contrastive_based import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = FakeDataset(num_graphs = 1, avg_num_nodes = 100, num_channels = 16, num_classes = 4)[0]\n",
    "dataset = RandomNodeSplit(split = \"random\", num_test = 20, num_val = 20, num_train_per_class=2)(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setup (for cora)\n",
    "benchmark_params = {\n",
    "    'downstream_epochs' : 100,\n",
    "    'pretext_epochs' : 100,\n",
    "    'downstream_lr' : 3e-4,\n",
    "    'pretext_lr' : 3e-4,\n",
    "    'patience': 50\n",
    "}\n",
    "\n",
    "h_params = {\n",
    "    'in_channels' : dataset.x.shape[1],\n",
    "    'hidden_channels' : 128,\n",
    "    'num_layers' : 2,\n",
    "    'dropout' : 0.5,\n",
    "}\n",
    "\n",
    "pretext_params = {\n",
    "    'k_largest': 3,\n",
    "}\n",
    "\n",
    "generator_config = {\n",
    "    'num_clusters' : 4,\n",
    "}\n",
    "\n",
    "pretext_task = GBT\n",
    "training_scheme = 'JL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [2.077744483947754,\n",
       "  2.1183090209960938,\n",
       "  2.1866650581359863,\n",
       "  1.994983434677124,\n",
       "  2.1369428634643555,\n",
       "  2.1827170848846436,\n",
       "  2.1895270347595215,\n",
       "  2.1424970626831055,\n",
       "  2.0182809829711914,\n",
       "  2.1954054832458496,\n",
       "  2.1860969066619873,\n",
       "  2.138559341430664,\n",
       "  2.1516246795654297,\n",
       "  2.1762094497680664,\n",
       "  2.2449827194213867,\n",
       "  2.200395107269287,\n",
       "  2.147204875946045,\n",
       "  2.1322169303894043,\n",
       "  2.126544952392578,\n",
       "  2.230757474899292,\n",
       "  2.1871700286865234,\n",
       "  2.0845561027526855,\n",
       "  2.013164758682251,\n",
       "  2.1193032264709473,\n",
       "  2.0269620418548584,\n",
       "  2.170285224914551,\n",
       "  2.059865713119507,\n",
       "  1.9964669942855835,\n",
       "  2.2515268325805664,\n",
       "  2.1031341552734375,\n",
       "  2.1207804679870605,\n",
       "  2.0589282512664795,\n",
       "  2.0802481174468994,\n",
       "  2.0812933444976807,\n",
       "  2.108333110809326,\n",
       "  2.1799678802490234,\n",
       "  2.068737268447876,\n",
       "  2.0405092239379883,\n",
       "  2.115757465362549,\n",
       "  2.2451400756835938,\n",
       "  2.1463088989257812,\n",
       "  1.980891227722168,\n",
       "  2.030233144760132,\n",
       "  2.0530927181243896,\n",
       "  2.100661039352417,\n",
       "  2.009232521057129,\n",
       "  2.033233880996704,\n",
       "  2.1026482582092285,\n",
       "  2.1131675243377686,\n",
       "  2.04170298576355,\n",
       "  2.0394182205200195,\n",
       "  2.168097496032715,\n",
       "  2.14094877243042,\n",
       "  2.031813144683838,\n",
       "  2.1471128463745117,\n",
       "  2.1314773559570312,\n",
       "  2.1224071979522705,\n",
       "  2.1437020301818848,\n",
       "  2.071685552597046,\n",
       "  2.140953302383423,\n",
       "  2.0432724952697754,\n",
       "  1.9842729568481445,\n",
       "  1.9568586349487305,\n",
       "  2.0093741416931152,\n",
       "  2.10978364944458,\n",
       "  2.1022019386291504,\n",
       "  2.0988125801086426,\n",
       "  2.0205881595611572,\n",
       "  1.9967856407165527,\n",
       "  2.1161649227142334,\n",
       "  2.1829187870025635,\n",
       "  2.133568286895752,\n",
       "  2.0412890911102295,\n",
       "  2.1468851566314697,\n",
       "  2.068232774734497,\n",
       "  2.0850706100463867,\n",
       "  2.126574993133545,\n",
       "  2.0034379959106445,\n",
       "  2.139711380004883,\n",
       "  2.1483821868896484,\n",
       "  2.0821011066436768,\n",
       "  2.1872220039367676,\n",
       "  2.0672407150268555],\n",
       " [7.104174064537252,\n",
       "  7.088359188734425,\n",
       "  7.069431789654847,\n",
       "  7.046833679894549,\n",
       "  7.020135247082213,\n",
       "  6.988683892503991,\n",
       "  6.947038563744229,\n",
       "  6.904875731844937,\n",
       "  6.861667378234254,\n",
       "  6.821943905955996,\n",
       "  6.7808640697284615,\n",
       "  6.739205755672293,\n",
       "  6.690006764168248,\n",
       "  6.640126869588883,\n",
       "  6.588643869221232,\n",
       "  6.541795380938299,\n",
       "  6.486452275307625,\n",
       "  6.428572009805367,\n",
       "  6.363296247701021,\n",
       "  6.281995004022532,\n",
       "  6.1955136446264865,\n",
       "  6.091562532997966,\n",
       "  5.966453862322683,\n",
       "  5.906135083026439,\n",
       "  5.3739693585207915,\n",
       "  5.360486129597294,\n",
       "  4.72557862021786,\n",
       "  3.7154577018537,\n",
       "  2.4358698606991256,\n",
       "  2.364848267495308,\n",
       "  2.1335586635997252,\n",
       "  2.2739711804383496,\n",
       "  2.1918170566953536,\n",
       "  2.504416673732437,\n",
       "  3.3634768552576046,\n",
       "  4.860956882012077,\n",
       "  5.530639701190166,\n",
       "  6.794815890372787,\n",
       "  8.781662430946321,\n",
       "  9.079823102078366,\n",
       "  8.810280452680415,\n",
       "  8.919688228033475,\n",
       "  9.061106501653352,\n",
       "  9.12853055997803,\n",
       "  9.187503864958764,\n",
       "  9.223658084633245,\n",
       "  9.261766265588054,\n",
       "  9.288019012115667,\n",
       "  9.307018790314133,\n",
       "  9.339017234934673,\n",
       "  9.396979517950106,\n",
       "  9.459881279297168,\n",
       "  9.88403458816437,\n",
       "  9.887265605893445,\n",
       "  9.896144110500462,\n",
       "  9.903393626487922,\n",
       "  9.930256579534827,\n",
       "  9.919888898250774,\n",
       "  9.908646777892038,\n",
       "  9.889566066395346,\n",
       "  9.849166692692515,\n",
       "  9.79912769674099,\n",
       "  9.778257417591647,\n",
       "  9.773050983750718,\n",
       "  9.727346284521117,\n",
       "  9.640983206725325,\n",
       "  9.59231959566114,\n",
       "  9.557412196488377,\n",
       "  9.500952184733896,\n",
       "  9.420497439134053,\n",
       "  9.305699519494851,\n",
       "  9.162896588359414,\n",
       "  8.93842024610603,\n",
       "  8.505414479009296,\n",
       "  8.40612408865725,\n",
       "  8.003935808000119,\n",
       "  7.979254365887654,\n",
       "  7.878123349360844,\n",
       "  7.361210569113505,\n",
       "  7.12363393075772,\n",
       "  6.396995751767022,\n",
       "  6.027187352541418,\n",
       "  4.177947184454104],\n",
       " [0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.4852430555555556,\n",
       "  0.6321180555555556,\n",
       "  0.6430555555555555,\n",
       "  0.5618055555555556,\n",
       "  0.5008680555555556,\n",
       "  0.5008680555555556,\n",
       "  0.5008680555555556,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.4953125,\n",
       "  0.4953125],\n",
       " {'accuracy': 0.3,\n",
       "  'f1_micro': 0.3,\n",
       "  'f1_macro': 0.25946275946275943,\n",
       "  'rocauc_ovr': 0.5208350166989872,\n",
       "  'rocauc_ovo': 0.5208350166989872,\n",
       "  'logloss': 1.3862943611198906},\n",
       " {'accuracy': 0.45,\n",
       "  'f1_micro': 0.45,\n",
       "  'f1_macro': 0.375,\n",
       "  'rocauc_ovr': 0.6430555555555555,\n",
       "  'rocauc_ovo': 0.6430555555555555,\n",
       "  'logloss': 2.1918170566953536})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training. You can attach a debugger to w/e is needed inside train\n",
    "benchmarker = NNNodeBenchmarkerSSL(generator_config=generator_config, model_class=GCN, \n",
    "                benchmark_params=benchmark_params, h_params=h_params,\n",
    "                pretext_task=pretext_task, pretext_params = pretext_params, training_scheme=training_scheme)\n",
    "benchmarker.SetMasks(train_mask=dataset.train_mask, val_mask=dataset.val_mask, test_mask=dataset.test_mask)\n",
    "benchmarker.train(data=dataset, tuning_metric=\"rocauc_ovr\", tuning_metric_is_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7ab25521b35298f0c482908cd2836fcd803c6b8449977de01eb4d32cc96d8dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
